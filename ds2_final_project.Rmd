---
title: "final_project_airbnb"
author: "Kwangmin Kim"
date: "April 19, 2018"
output: html_document
---
##clean and tidy the airbnb data

```{r load packages, include=FALSE}
library(tidyverse)
library(janitor)
library(stringr)
library(forcats)
library(viridis)
library(plotly)
library(ISLR)
library(caret)
library(corrplot)
library(tree)
library(rpart)
library(glmnet)
library(randomForest)
library(gbm)
library(adabag)
library(e1071)
library(MASS)
library(pROC)
library(partykit)
library(boot)
library(pls)
library(gam)
```

```{r clean and tidy data, include = FALSE}
airbnb = read_csv("./data/nyc_airbnb.zip")

airbnb_initial = airbnb%>%
  clean_names()%>%
  mutate(rating = review_scores_location / 2)%>%
  dplyr::select(id, boro = neighbourhood_group, neighbourhood, rating, reviews_per_month, number_of_reviews, price, room_type, reviews_per_month, availability_365, calculated_host_listings_count, minimum_nights, latitude, longitude) %>% 
  filter(price %in% 30:500) 

airbnb_data = airbnb_initial %>%
  mutate(room_type = as.numeric(as.factor(room_type)),
         boro = as.numeric(as.factor(boro)),
         neighbourhood = as.numeric(as.factor(neighbourhood))) 
airbnb_data[, 4:5][is.na(airbnb_data[, 4:5])] = 0
```


```{r some basic plots }
#plotly scatter plot

airbnb_data %>%
  mutate(text_label = str_c("Price: $", price, '\nRating: ', rating)) %>% 
  plot_ly(x = ~longitude, y = ~latitude, type = "scatter", mode = "markers",
          alpha = 0.5, 
          color = ~price,
          text = ~text_label)

common_neighborhoods = airbnb_initial %>% 
  count(neighbourhood, sort = TRUE) %>% 
  top_n(8) %>% 
  dplyr::select(neighbourhood)

#neighborhood-price
inner_join(airbnb_initial, common_neighborhoods, by = "neighbourhood")%>%
  mutate(neighbourhood = fct_reorder(neighbourhood, price)) %>% 
  plot_ly(y = ~price, color = ~neighbourhood, type = "box",
          colors = "Set2")
#frequencty of popular neighborhood
airbnb_initial %>% 
  count(neighbourhood) %>% 
  mutate(neighbourhood = fct_reorder(neighbourhood, n)) %>% 
  plot_ly(x = ~neighbourhood, y = ~n, color = ~neighbourhood, type = "bar")


airbnb_initial %>% 
  count(neighbourhood) %>%
  arrange(desc(n))
```

```{r}
#corplot
corr<-airbnb_data%>%
  dplyr::select(-boro , -neighbourhood, -room_type, -latitude, -longitude)
corrplot(cor(corr), method="square",shade.col=NA, tl.col="black", tl.srt=45)
```


```{r Linear}
numeric_data = airbnb_data%>%
  dplyr::select(price,everything(),-boro, -neighbourhood, -room_type, -longitude, -latitude)

plot(numeric_data$price)
featurePlot(x=numeric_data[,2:5],y=numeric_data$price, plot = 'pairs')

#splitting data into train and test
sample_size=floor(0.75*nrow(numeric_data))

set.seed(1)

sample_air = sample(seq_len(nrow(numeric_data)), size = sample_size)
train = numeric_data[sample_air, ]
test = numeric_data[-sample_air, ]

#LSE on the traing data
ln_model = lm(price~., data=train)
pred_data = predict(ln_model, test)
test_error1 = mean((pred_data-test$price)^2)#4777.552

```

```{r Ridge}
#ridge regression
x_test = model.matrix(price~.,train)[,-1]
y_test = train$price
grid_ridge = 10^seq(10.,-5, length = 1000)

ridge_model = glmnet(x_test,y_test,alpha=0,lambda = grid_ridge)
cv.out = cv.glmnet(x_test,y_test,alpha=0, lambda = grid_ridge,
                   type.measure = "mse")
plot(cv.out)
best_lambda1 = round(cv.out$lambda.min,3);best_lambda1#0.178

best_ridge_mod = glmnet(x_test,y_test,alpha=0,lambda = best_lambda1)

reg_pred=predict(best_ridge_mod ,s=best_lambda1,newx=x_test)

test_error2= round(mean((reg_pred-y_test)^2),3);test_error2#4859.771
```


```{r Lasso}
set.seed(2)

grid_lasso = exp(seq(1,-8,length=100))
lasso_mod = glmnet(x_test,y_test,alpha=1,lambda= grid_lasso)

cv.out2 = cv.glmnet(x_test,y_test,alpha=1,lambda= grid_lasso)
best_lambda2 = round(cv.out2$lambda.min, 3);best_lambda2#0.28

plot(cv.out2)

pred_lasso = predict(lasso_mod ,s=best_lambda2, newx=x_test)
test_error3 = mean((pred_lasso-y_test)^2);test_error3#4860.522


coefficients = predict(lasso_mod, s=best_lambda2, type="coefficients") %>%
  as.matrix()
non_zero_coeff = coefficients[coefficients[,1] != 0,]
non_zero_coeff%>% knitr::kable()
```


```{r PCR}
set.seed(3)
# pcr
# matrix of predictors
x = model.matrix(price~.,airbnb_data)[,-1]
# vector of response
y = airbnb_data$price

# create traing set
trRows <- createDataPartition(y,
                              p = .50,
                              list = F)

# implementation using package pls
# pcr
pcr.fit = pcr(price~., 
              data = airbnb_data,
              subset = trRows,
              scale = TRUE, # standardize the predictors!!
              validation = "CV")
summary(pcr.fit)
validationplot(pcr.fit,val.type="MSEP")
# test set performance
pcr.pred = predict(pcr.fit,x[-trRows,],ncomp=5)
test_error4 = round(mean((pcr.pred-y[-trRows])^2),3);test_error4 #4564.748

```

```{r PLS}
# pls
pls.fit = plsr(price~., 
               data=airbnb_data, 
               scale=TRUE,  
               subset = trRows,
               validation ="CV")
summary(pls.fit)
validationplot(pls.fit,val.type="MSEP")
# test set performance
pls.pred = predict(pls.fit,x[-trRows,],ncomp=2)
test_error5 = round(mean((pls.pred-y[-trRows])^2),3);test_error5# 4209.287
```


```{r MSE}
MSE=matrix(c(test_error1,test_error2,test_error3,test_error4, test_error5))
rownames(MSE) <- c("Linear", "Ridge","Lasso", "PCR", "PLS") 
colnames(MSE) = "Test Errors from Each Model"
MSE
```
Our team applies the shrinking techniques such as Ridge, Lasso, PCR(Principle Component Analysis),PLS(Partial Least Square) into the airbnb data set. The criteria for selecting the best model is the selection of the lowest test error among those of the srinking methods mentioned above. For each model, we found method-specific tuning parameters. The ridge regression with the best tune parameter `r best_lambda1`  has `r test_error2` test error close to `test_error1` of LSE because the tune parameter is close to 0. The Lasso model with the compensation of variable selections for the drawback of ridge regression yields sparse models involving a subset of variables. Although by using lasso, we expected reduced variance at the cost of small increase in bias, its best lamda is `r best_lambda2` and test error is `r test_error3`. After that, PCR was used as another technique of deriving a low dimensional set of features from a large set of variables. The first principal component direction of the data is that along which the observations vary the most. As the result, `r test_error4` of the smaller test error was obtained. Lastly, pls is used as a supervised alternative to PCR whose test error is `r test_error5`, the smallest one. 
```{r polynomial}
airbnb_data2=airbnb_data%>%
  dplyr::select(-longitude,-latitude)%>%
  mutate(room_type = as.numeric(as.factor(room_type)))


x = model.matrix(price~.,airbnb_data2)[,-1]
y = airbnb_data2$price
featurePlot(x,y)

set.seed(4)

deltas <- rep(NA, 7)
for (i in 1:7) {
  fit <- glm(price ~ poly(rating, i), data = airbnb_data2)
  deltas[i] <- cv.glm(airbnb_data2, fit, K = 7)$delta[1]
}
plot(1:7, deltas, xlab = "Degree", ylab = "Test MSE", type = "l")
delta.min <- which.min(deltas);delta.min 
points(which.min(deltas), deltas[which.min(deltas)], col = "red", cex = 2, pch = 20)

fit1 <- lm(price ~ rating, data = airbnb_data2)
fit2 <- lm(price ~ poly(rating, 2), data = airbnb_data2)
fit3 <- lm(price ~ poly(rating, 3), data = airbnb_data2)
fit4 <- lm(price ~ poly(rating, 4), data = airbnb_data2)
fit5 <- lm(price ~ poly(rating, 5), data = airbnb_data2)
fit6 <- lm(price ~ poly(rating, 6), data = airbnb_data2)
fit7 <- lm(price ~ poly(rating, 7), data = airbnb_data2)
#fit1-7 are nested, possible to use anova to test 
anova(fit1, fit2, fit3, fit4, fit5, fit6, fit7)
#fit.5 has optimal.
summary(fit5)
fit5$df#39694

plot(price ~ rating, data = airbnb_data2, col = "darkgrey")
price_range <- range(airbnb_data2$rating)
price.grid <- seq(from = price_range[1], to = price_range[2])
fit <- lm(price ~ poly(rating, 7), data = airbnb_data2)
preds <- predict(fit, newdata = list(rating = price.grid))
lines(price.grid, preds, col = "red", lwd = 2)
```
When d = 5 by cross validation, the polynomial has the optimal degree. However, considering P value and RSS, the best degree of freedom by anova test is d = 4.
```{r Spline}
rss = rep(NA, 40)
for (i in 3:40) {
  fit = lm(price ~ bs(rating, df = i), data = airbnb_data2)
  rss[i] <- sum(fit$residuals^2)
}
plot(3:40, rss[-c(1, 2)], xlab = "Degrees of freedom", ylab = "RSS", type = "l")
rss

```
From d =4, the RSS extremely decreased. After that, the subsequent increased df has similar RSS
```{r GAM}
gam = gam(price ~ s(boro) + s(neighbourhood) + 
            s(rating) + s(calculated_host_listings_count) + s(number_of_reviews) +
            s(availability_365), data = airbnb_data2)
par(mfrow = c(2, 3))
plot(gam, se=TRUE,col="blue")
```

Using 6 predictors, I fit a GAM where price has approximately linear positive associations with availability_365 and negative association with number of reviews. The plot also shows that the low rating has lower prices except for '0' rating, which seem to be quadratic. The higher rating is, the higher price is. In Manhattan, price is much higher than that of the other boroughs. In addition, it seems that the association between price and neighbourhood has the fourth degree polynomial.

```{r price regression tree}
set.seed(46)

airbnb_an = airbnb_data %>%
  dplyr::select(-id, -neighbourhood, -latitude, -longitude) 
train_price_tree = sample(1:nrow(airbnb_an), nrow(airbnb_an)/2)
train_pt = airbnb_an[train_price_tree,]
test_pt = airbnb_an[-train_price_tree,]

fit_price = rpart(price ~ ., data = train_pt)
printcp(fit_price)

#summary(fit_price) # detailed summary of splits

prune_fit_price = prune(fit_price, cp = 0.013153)
#summary(prune_fit_price)

pred_fit_price = predict(prune_fit_price, newdata = test_pt)

price_tree_mse = mean((pred_fit_price - test_pt$price)^2)
price_tree_mse
```


```{r LDA}
set.seed(4)

train_lq = sample(1:dim(airbnb_an)[1], 15000, replace = FALSE)
lda_train = airbnb_an[train_lq,]
lda_test = airbnb_an[-train_lq,]

lda.fit = lda(boro ~ ., data = lda_train)

lda.pred = predict(lda.fit, newdata = lda_test)

lda_test_error = mean(lda.pred$class == lda_test$boro)
lda_test_error #0.5699


qda.fit = qda(boro ~ ., data = lda_train)

qda.pred = predict(qda.fit, data = lda_test)

#qda_test_error = mean(qda.pred$class == lda_test$boro)
#need error 
```

```{r boro classification tree}
airbnb_tree_data = dplyr::select(airbnb_initial, -neighbourhood, -reviews_per_month, -latitude, -longitude)

set.seed(123)
n = nrow(airbnb_tree_data)
trainIndex = sample(1:n, size = round(0.5*n), replace=FALSE)
airbnb_tree_train = airbnb_tree_data[trainIndex ,]
airbnb_tree_test = airbnb_tree_data[-trainIndex ,]


#pruned tree
tree.airbnb <- tree(boro ~ ., data = airbnb_tree_train)
summary(tree.airbnb)

cv.tree.airbnb <- cv.tree(tree.airbnb, FUN = prune.misclass)
minsize=cv.tree.airbnb$size[which.min(cv.tree.airbnb_data$dev)]

prune.tree.airbnb <- prune.misclass(tree.airbnb, best = minsize)
summary(prune.tree.airbnb)

#pruned tree plot
plot(prune.tree.airbnb)
text(prune.tree.airbnb, pretty = 0)

#prediction
predict.pruned.tree <- predict(prune.tree.airbnb, airbnb_tree_test, type='class')
table(predict.pruned.tree, airbnb_tree_test$boro)

basic.mse=mean(predict.pruned.tree != airbnb_tree_test$boro)
basic.mse
```
For borough, we can't apply Ridge/Lasso, instead we adopt Classification tree to have an elementary analysis of the relationship between the borough and other covariates. We establish a model with pruned parameter which we obtain from the cross-validation, for the best tree size. And the optimal tree size equals to 3, the training data error rate is 0.4531. Use test dataset to predict, the error rate is 0.4472914.  

```{r bagging}
bag.airbnb <- randomForest(boro ~ ., data = airbnb_tree_train, mtry = 10, ntree = 500, importance = TRUE)
pred.bag.airbnb <- predict(bag.airbnb, newdata = airbnb_tree_test)
table(pred.bag.airbnb, airbnb_tree_test$boro )
bag.mse=mean(pred.bag.airbnb!= airbnb_tree_test$boro )
bag.mse
#0.4122854 is test error.
varImpPlot(bag.airbnb)
#price, room type and availability is important
```
Later on, we want to get a more powerful model with improved performance of simple pruned classification tree model. So we use bagging, which instead of fitting the model on one sample of the population, several models are fitted on different samples (with replacement) of the population. Then, these models are aggregated by using their average, weighted average or a voting system (mainly for classification). test error blahblahblah importance blahblahblah...


```{r random forest}
rf.airbnb <- randomForest(boro ~ ., data = airbnb_tree_train, mtry = 5, ntree = 500, importance = TRUE)
pred.rf.airbnb <- predict(rf.airbnb, newdata = airbnb_tree_test)
table(pred.rf.airbnb, airbnb_tree_test$boro )
rf.mse=mean(pred.rf.airbnb!= airbnb_tree_test$boro )
rf.mse
#0.4082923 test error
varImpPlot(rf.airbnb)
##price and availability is important
```
Random forest has a advantage of balancing the Biase-Variance Tradeoff and creates a more strong model. And random forest is commonly used to improve the predictive performance of Decision Trees by reducing the variance in the Trees by averaging them. test error blahblahblah importance blahblahblah...

```{r boost}
airbnb_tree_train$boro <- as.numeric(airbnb_tree_train$boro == "Manhattan") 
airbnb_tree_test$boro <- as.numeric(airbnb_tree_test$boro == "Manhattan") 
boost.airbnb = gbm(boro ~ ., data = airbnb_tree_train, distribution = "bernoulli", n.trees = 5000, interaction.depth = 4)
yhat.boost = predict(boost.airbnb, newdata = airbnb_tree_test,
n.trees = 5000, type = "response")
pred.boost.airbnb <- ifelse(yhat.boost > 0.5, 1, 0)
table(pred.boost.airbnb, airbnb_tree_test$boro)
boost.mse = (2250 + 2493)/(2250 + 5706 + 2493 + 4577)
#(2250 + 2493)/(2250 + 5706 + 2493 + 4577) =  0.315652   test error
summary(boost.airbnb)
#price is important.And room type, rating and availability are also important.
```
Bagging the various models which are generated are independent of each other and have equal weightage .Whereas Boosting is a sequential process in which each next model which is generated is added so as to improve a bit from the previous model.Simply saying each of the model that is added to mix is added so as to improve on the performance of the previous collection of models.In Boosting we do weighted averaging. Boost can be more efficient than bagging, so we use boost here. test error blahblahblah importance blahblahblah...


```{r compare}
compare_df = data.frame(Boosting_MSE = boost.mse, Random_forest_MSE =rf.mse, Bagging_MSE = bag.mse, Decision_trees_MSE = basic.mse)
compare_df
```

Among these methods, boosting gives the best result on this data based on the test error rates. Pruned classification tree has the worest performance.Random forest and bagging have similar test error rates as well as the performance. Since the data has many predictors, boosting might be easier to tune and less possible to overfit the data than other methods.

```{r svm_linear}
airbnb_svm_data = dplyr::select(airbnb_initial, -neighbourhood, -reviews_per_month, -latitude, -longitude)

set.seed(123)
n = nrow(airbnb_svm_data)
trainIndex = sample(1:n, size = round(0.5*n), replace=FALSE)
airbnb_svm_train = airbnb_svm_data[trainIndex ,]
airbnb_svm_test = airbnb_svm_data[-trainIndex ,]


svm.linear <- svm(boro ~ ., data = airbnb_svm_train, 
                 kernel = "linear",
                 cost = 0.01)
summary(svm.linear)
test.pred <- predict(svm.linear, newdata = airbnb_svm_test)
table(airbnb_svm_test$boro, test.pred)
mean(airbnb_svm_test$boro != test.pred)
#for svm linear model, 0.4257287 is the test error rate
```
Support Vector Machines (SVM) is a data classification method that separates data using hyperplanes and is very useful to data whose distribution is unknown. test error blahblahblah importance blahblahblah...

```{r}
set.seed(5)
tune.out <- tune(svm, boro ~ ., data= airbnb_svm_train, 
                 kernel="linear",
                 ranges=list(cost=c(0.01,0.1,1,10,100),
                          gamma=c(0.001,0.01,0.1,0.5,1) ))
summary(tune.out)
```

